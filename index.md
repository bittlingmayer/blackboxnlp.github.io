# Analyzing and interpreting neural networks for NLP

*Revealing the content of the neural black box: workshop on the analysis and interpretation of neural networks for Natural Language Processing.*


## Venue and date

The workshop will be collocated with EMNLP 2018 in Brussels. 
The workshops will be held on October 31 and November 1.

## Description
Neural networks have rapidly become a central component in NLP systems in the last few years. The improvement in accuracy and performance brought by the introduction of neural networks has typically come at the cost of our understanding of the system: what are the representations and computations that the network learns? The goal of this workshop is to bring together people who are attempting to peek inside the neural network black box, taking inspiration from machine learning, psychology, linguistics and neuroscience. The topics of the workshop will include, but are not limited to:


- Applying analysis techniques from neuroscience to analyze high-dimensional vector representations (such as Haxby et al., 2001; Kriegeskorte, 2008) in artificial neural networks;
- Analyzing the network's response to strategically chosen inputs in order to infer the linguistic generalizations that the network has acquired (e.g., Linzen et al., 2016);
- Examining the performance of the network on simplified or formal languages;
- Proposing modifications to neural network architectures that can make them more interpretable (e.g., Palangi et al., 2017);
- Scaling up neural network analysis techniques developed in the connectionist literature in the 1990s (Elman, 1991);
- Testing whether interpretable information can be decoded from intermediate representations (e.g., Adi et al.,  2017; Chrupała et al., 2017);
- Translating insights on neural networks interpretation from the vision domain (e.g., Zeiler & Fergus, 2014) to language.

In addition to full papers, we will encourage the submission of non-archival extended abstracts.


## Organizers

**[Tal Linzen](http://tallinzen.net/)** is an Assistant Professor of Cognitive Science at Johns Hopkins University. He develops computational cognitive models of language. In addition to his work in psycholinguistics and cognitive neuroscience, he has studied the syntactic capabilities of contemporary artificial neural networks and the linguistic information encoded in word embeddings, in work that has appeared in TACL, EACL and CoNLL. He has co-organized the workshop on Cognitive Modeling and Computational Linguistics which was co-located with EACL 2017, and is co-organizing the next installation of the same workshop at the Society for Computation in Linguistics in January 2018.

**[Afra Alishahi](https://ilk.uvt.nl/~aalishah/)** is an Associate Professor of Cognitive Science and Artificial Intelligence at Tilburg University, the Netherlands. Her main research interest is developing computational models for studying the process of human language acquisition. Recently she has been studying the emergence of linguistic structure in grounded models of language learning. She has chaired CoNLL 2015, and organized the EACL Workshop on Cognitive Aspects of Computational Language Acquisition in 2009.

**[Grzegorz Chrupała](http://grzegorz.chrupala.me)** is an Assistant Professor at the Department of Cognitive Science and Artificial Intelligence at Tilburg University. His recent research focus has been on computational models of language learning  from multimodal signals such as speech and vision and on the analysis of linguistic representations emerging in multilayer recurrent neural networks. He was Area Co-Chair for Machine Learning at ACL 2017.
